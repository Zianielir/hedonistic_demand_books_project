{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ab3884",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48752e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t, f, boxcox, skew, kurtosis, gmean\n",
    "from statsmodels.stats.diagnostic import linear_reset, het_white\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b9e40",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a044d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_after_processing.csv', encoding='utf-8')\n",
    "\n",
    "data = data.drop(['title', 'Unnamed: 0'], axis=1)\n",
    "data = data.drop(['author_Другой', 'publisher_Другой', 'publication_year_Другой',\n",
    "                  'cover_type_Мягкий заламинированный картон', 'reading_age_6+'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d248d",
   "metadata": {},
   "source": [
    "### Логарифм цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9b56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_price'] = np.log(data['price'])\n",
    "data = data.drop(['price'], axis=1)\n",
    "y = data['log_price']\n",
    "X = data.drop(['log_price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53359e85",
   "metadata": {},
   "source": [
    "### Регрессоры, которые можно логарифмировать и нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef7b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_try_log = [\n",
    "    'avg_rating', 'cnt_reviews', 'pages_cnt', 'tirage', \n",
    "    'weight', 'thickness', 'width', 'length', 'volume'\n",
    "]\n",
    "\n",
    "unconditional_cols = [x for x in X.columns.tolist() if x not in cols_to_try_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc5da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_combinations(num_of_repeats):\n",
    "    \"\"\"Генерирует все комбинации признаков, к которым применяется функциональное преобразование\"\"\"\n",
    "    return product([False, True], repeat=num_of_repeats)\n",
    "\n",
    "def prepare_X(cols_to_try_func, combination, df, func):\n",
    "    \"\"\"Создает матрицу X для текущей комбинации\"\"\"\n",
    "    \"\"\"Примеры функций: np.log, np.power, np.reciprocal, ...\"\"\"\n",
    "    X_temp = df[unconditional_cols].copy()\n",
    "    feature_name = getattr(func, '__name__', repr(func))\n",
    "    \n",
    "    for i, col in enumerate(cols_to_try_func):\n",
    "        if combination[i]:\n",
    "            try:\n",
    "                safe_col = df[col]\n",
    "                if (safe_col <= 0).any() and (func == np.log) or (func == np.reciprocal):\n",
    "                    safe_col = safe_col + 1e-6\n",
    "                X_temp[f'{feature_name}_{col}'] = func(safe_col)\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при применении функции к {col}: {e}\")\n",
    "        else:\n",
    "            X_temp[col] = df[col]\n",
    "    \n",
    "    return sm.add_constant(X_temp)\n",
    "\n",
    "def getting_statistic(cols_to_try_func, df, func):\n",
    "    results = []\n",
    "\n",
    "    total_combinations = 2 ** len(cols_to_try_func)\n",
    "    feature_name = getattr(func, '__name__', repr(func))\n",
    "\n",
    "    for combination in tqdm(generate_all_combinations(num_of_repeats=len(cols_to_try_func)), total=total_combinations):\n",
    "        try:\n",
    "            # Подготавливаем данные\n",
    "            X_curr = prepare_X(cols_to_try_func, combination, df, func)\n",
    "\n",
    "            model = sm.OLS(df['log_price'], X_curr).fit()\n",
    "            results.append({\n",
    "                'combination': combination,\n",
    "                'aic': model.aic,\n",
    "                'bic': model.bic,\n",
    "                'adj_r2': model.rsquared_adj,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in combination {combination}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results[f'{feature_name}_columns'] = df_results['combination'].apply(\n",
    "        lambda x: [cols_to_try_func[i] for i, my_func in enumerate(x) if my_func]\n",
    "    )\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68d0577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 512/512 [00:07<00:00, 72.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель по AIC:\n",
      "Логарифмированные переменные: ['tirage']\n",
      "AIC: -297.99\n",
      "\n",
      "Лучшая модель по BIC:\n",
      "Логарифмированные переменные: ['tirage']\n",
      "BIC: -84.86\n",
      "\n",
      "Лучшая модель по Adj.R²:\n",
      "Логарифмированные переменные: ['tirage']\n",
      "Adj.R²: 0.8021\n"
     ]
    }
   ],
   "source": [
    "# Проверяем логарифмирование\n",
    "data_frame = getting_statistic(cols_to_try_func=cols_to_try_log, df=data, func=np.log)\n",
    "\n",
    "best_aic = data_frame.loc[data_frame['aic'].idxmin()]\n",
    "best_bic = data_frame.loc[data_frame['bic'].idxmin()]\n",
    "best_adj_r2 = data_frame.loc[data_frame['adj_r2'].idxmax()]\n",
    "\n",
    "print(\"Лучшая модель по AIC:\")\n",
    "print(f\"Логарифмированные переменные: {best_aic['log_columns']}\")\n",
    "print(f\"AIC: {best_aic['aic']:.2f}\\n\")\n",
    "\n",
    "print(\"Лучшая модель по BIC:\")\n",
    "print(f\"Логарифмированные переменные: {best_bic['log_columns']}\")\n",
    "print(f\"BIC: {best_bic['bic']:.2f}\\n\")\n",
    "\n",
    "print(\"Лучшая модель по Adj.R²:\")\n",
    "print(f\"Логарифмированные переменные: {best_adj_r2['log_columns']}\")\n",
    "print(f\"Adj.R²: {best_adj_r2['adj_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d333052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 512/512 [00:07<00:00, 68.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель по AIC:\n",
      "Преобразованные переменные: []\n",
      "AIC: -215.04\n",
      "\n",
      "Лучшая модель по BIC:\n",
      "Преобразованные переменные: []\n",
      "BIC: -1.90\n",
      "\n",
      "Лучшая модель по Adj.R²:\n",
      "Преобразованные переменные: []\n",
      "Adj.R²: 0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Проверяем признаки вида 1/x\n",
    "my_func = np.reciprocal\n",
    "data_frame = getting_statistic(cols_to_try_func=cols_to_try_log, df=data, func=my_func)\n",
    "\n",
    "best_aic = data_frame.loc[data_frame['aic'].idxmin()]\n",
    "best_bic = data_frame.loc[data_frame['bic'].idxmin()]\n",
    "best_adj_r2 = data_frame.loc[data_frame['adj_r2'].idxmax()]\n",
    "\n",
    "column_name = f'{my_func.__name__}_columns'\n",
    "\n",
    "print(\"Лучшая модель по AIC:\")\n",
    "print(f\"Преобразованные переменные: {best_aic[column_name]}\")\n",
    "\n",
    "print(f\"AIC: {best_aic['aic']:.2f}\\n\")\n",
    "\n",
    "print(\"Лучшая модель по BIC:\")\n",
    "print(f\"Преобразованные переменные: {best_bic[column_name]}\")\n",
    "print(f\"BIC: {best_bic['bic']:.2f}\\n\")\n",
    "\n",
    "print(\"Лучшая модель по Adj.R²:\")\n",
    "print(f\"Преобразованные переменные: {best_adj_r2[column_name]}\")\n",
    "print(f\"Adj.R²: {best_adj_r2['adj_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb444f",
   "metadata": {},
   "source": [
    "Также функции будут работать, если мы решим проверить какие-то кастомные функции типо этого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b224d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_shift(x):\n",
    "    return x**2 + 3*x + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdf5f5",
   "metadata": {},
   "source": [
    "### Итоговая модель с ln Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c8210",
   "metadata": {},
   "source": [
    "После проверки всех функциональных форм обучаем итоговую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6148792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   389.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 May 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:37:26</td>     <th>  Log-Likelihood:    </th> <td>  184.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3260</td>      <th>  AIC:               </th> <td>  -298.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3225</td>      <th>  BIC:               </th> <td>  -84.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    34</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                           <td>    5.8943</td> <td>    0.280</td> <td>   21.032</td> <td> 0.000</td> <td>    5.345</td> <td>    6.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tirage</th>                          <td>   -0.1782</td> <td>    0.010</td> <td>  -17.857</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_rating</th>                      <td>    0.0731</td> <td>    0.012</td> <td>    6.256</td> <td> 0.000</td> <td>    0.050</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cnt_reviews</th>                     <td>    0.0004</td> <td> 3.51e-05</td> <td>   10.025</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pages_cnt</th>                       <td>   -0.0003</td> <td> 4.17e-05</td> <td>   -7.621</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>                          <td>    0.0022</td> <td> 4.78e-05</td> <td>   45.115</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thickness</th>                       <td>    0.1769</td> <td>    0.022</td> <td>    8.167</td> <td> 0.000</td> <td>    0.134</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>width</th>                           <td>    0.0760</td> <td>    0.005</td> <td>   14.086</td> <td> 0.000</td> <td>    0.065</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length</th>                          <td>    0.0247</td> <td>    0.004</td> <td>    6.256</td> <td> 0.000</td> <td>    0.017</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volume</th>                          <td>   -0.0012</td> <td>    8e-05</td> <td>  -14.696</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Джейн Остен</th>              <td>    0.0134</td> <td>    0.028</td> <td>    0.469</td> <td> 0.639</td> <td>   -0.042</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Джек Лондон</th>              <td>   -0.0741</td> <td>    0.028</td> <td>   -2.678</td> <td> 0.007</td> <td>   -0.128</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Джордж Оруэлл</th>            <td>    0.0155</td> <td>    0.029</td> <td>    0.526</td> <td> 0.599</td> <td>   -0.042</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Лев Толстой</th>              <td>   -0.1152</td> <td>    0.031</td> <td>   -3.681</td> <td> 0.000</td> <td>   -0.177</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Луиза Мэй Олкотт</th>         <td>   -0.0343</td> <td>    0.033</td> <td>   -1.048</td> <td> 0.295</td> <td>   -0.098</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Михаил Булгаков</th>          <td>    0.0616</td> <td>    0.027</td> <td>    2.285</td> <td> 0.022</td> <td>    0.009</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Николай Гоголь</th>           <td>   -0.0944</td> <td>    0.033</td> <td>   -2.843</td> <td> 0.004</td> <td>   -0.159</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Федор Достоевский</th>        <td>   -0.1019</td> <td>    0.021</td> <td>   -4.813</td> <td> 0.000</td> <td>   -0.143</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_Эрих Ремарк</th>              <td>    0.1047</td> <td>    0.030</td> <td>    3.547</td> <td> 0.000</td> <td>    0.047</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_АСТ</th>                   <td>   -0.1477</td> <td>    0.030</td> <td>   -4.911</td> <td> 0.000</td> <td>   -0.207</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_Азбука</th>                <td>   -0.2000</td> <td>    0.031</td> <td>   -6.402</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_Иностранка</th>            <td>   -0.1291</td> <td>    0.036</td> <td>   -3.621</td> <td> 0.000</td> <td>   -0.199</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_Манн, Иванов и Фербер</th> <td>    0.0127</td> <td>    0.041</td> <td>    0.313</td> <td> 0.754</td> <td>   -0.067</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publisher_Эксмо</th>                 <td>   -0.1713</td> <td>    0.030</td> <td>   -5.617</td> <td> 0.000</td> <td>   -0.231</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publication_year_2021</th>           <td>   -0.0061</td> <td>    0.045</td> <td>   -0.133</td> <td> 0.894</td> <td>   -0.095</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publication_year_2022</th>           <td>    0.0386</td> <td>    0.038</td> <td>    1.016</td> <td> 0.310</td> <td>   -0.036</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publication_year_2023</th>           <td>    0.0400</td> <td>    0.037</td> <td>    1.095</td> <td> 0.274</td> <td>   -0.032</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publication_year_2024</th>           <td>    0.0580</td> <td>    0.036</td> <td>    1.614</td> <td> 0.107</td> <td>   -0.012</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>publication_year_2025</th>           <td>    0.0672</td> <td>    0.036</td> <td>    1.858</td> <td> 0.063</td> <td>   -0.004</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cover_type_Мягкий переплёт</th>      <td>   -0.2338</td> <td>    0.230</td> <td>   -1.015</td> <td> 0.310</td> <td>   -0.685</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cover_type_Твёрдый переплёт</th>     <td>   -0.0790</td> <td>    0.230</td> <td>   -0.343</td> <td> 0.731</td> <td>   -0.530</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reading_age_0+</th>                  <td>   -0.0317</td> <td>    0.144</td> <td>   -0.221</td> <td> 0.825</td> <td>   -0.313</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reading_age_12+</th>                 <td>   -0.2551</td> <td>    0.051</td> <td>   -5.025</td> <td> 0.000</td> <td>   -0.355</td> <td>   -0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reading_age_16+</th>                 <td>   -0.1734</td> <td>    0.050</td> <td>   -3.462</td> <td> 0.001</td> <td>   -0.272</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reading_age_18+</th>                 <td>   -0.0390</td> <td>    0.054</td> <td>   -0.727</td> <td> 0.467</td> <td>   -0.144</td> <td>    0.066</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>471.757</td> <th>  Durbin-Watson:     </th> <td>   2.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5130.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.304</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.116</td>  <th>  Cond. No.          </th> <td>1.03e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.03e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                   &    log\\_price    & \\textbf{  R-squared:         } &     0.804   \\\\\n",
       "\\textbf{Model:}                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.802   \\\\\n",
       "\\textbf{Method:}                          &  Least Squares   & \\textbf{  F-statistic:       } &     389.4   \\\\\n",
       "\\textbf{Date:}                            & Mon, 05 May 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                            &     17:37:26     & \\textbf{  Log-Likelihood:    } &    184.00   \\\\\n",
       "\\textbf{No. Observations:}                &        3260      & \\textbf{  AIC:               } &    -298.0   \\\\\n",
       "\\textbf{Df Residuals:}                    &        3225      & \\textbf{  BIC:               } &    -84.86   \\\\\n",
       "\\textbf{Df Model:}                        &          34      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                            &       5.8943  &        0.280     &    21.032  &         0.000        &        5.345    &        6.444     \\\\\n",
       "\\textbf{tirage}                           &      -0.1782  &        0.010     &   -17.857  &         0.000        &       -0.198    &       -0.159     \\\\\n",
       "\\textbf{avg\\_rating}                      &       0.0731  &        0.012     &     6.256  &         0.000        &        0.050    &        0.096     \\\\\n",
       "\\textbf{cnt\\_reviews}                     &       0.0004  &     3.51e-05     &    10.025  &         0.000        &        0.000    &        0.000     \\\\\n",
       "\\textbf{pages\\_cnt}                       &      -0.0003  &     4.17e-05     &    -7.621  &         0.000        &       -0.000    &       -0.000     \\\\\n",
       "\\textbf{weight}                           &       0.0022  &     4.78e-05     &    45.115  &         0.000        &        0.002    &        0.002     \\\\\n",
       "\\textbf{thickness}                        &       0.1769  &        0.022     &     8.167  &         0.000        &        0.134    &        0.219     \\\\\n",
       "\\textbf{width}                            &       0.0760  &        0.005     &    14.086  &         0.000        &        0.065    &        0.087     \\\\\n",
       "\\textbf{length}                           &       0.0247  &        0.004     &     6.256  &         0.000        &        0.017    &        0.032     \\\\\n",
       "\\textbf{volume}                           &      -0.0012  &        8e-05     &   -14.696  &         0.000        &       -0.001    &       -0.001     \\\\\n",
       "\\textbf{author\\_Джейн Остен}              &       0.0134  &        0.028     &     0.469  &         0.639        &       -0.042    &        0.069     \\\\\n",
       "\\textbf{author\\_Джек Лондон}              &      -0.0741  &        0.028     &    -2.678  &         0.007        &       -0.128    &       -0.020     \\\\\n",
       "\\textbf{author\\_Джордж Оруэлл}            &       0.0155  &        0.029     &     0.526  &         0.599        &       -0.042    &        0.073     \\\\\n",
       "\\textbf{author\\_Лев Толстой}              &      -0.1152  &        0.031     &    -3.681  &         0.000        &       -0.177    &       -0.054     \\\\\n",
       "\\textbf{author\\_Луиза Мэй Олкотт}         &      -0.0343  &        0.033     &    -1.048  &         0.295        &       -0.098    &        0.030     \\\\\n",
       "\\textbf{author\\_Михаил Булгаков}          &       0.0616  &        0.027     &     2.285  &         0.022        &        0.009    &        0.114     \\\\\n",
       "\\textbf{author\\_Николай Гоголь}           &      -0.0944  &        0.033     &    -2.843  &         0.004        &       -0.159    &       -0.029     \\\\\n",
       "\\textbf{author\\_Федор Достоевский}        &      -0.1019  &        0.021     &    -4.813  &         0.000        &       -0.143    &       -0.060     \\\\\n",
       "\\textbf{author\\_Эрих Ремарк}              &       0.1047  &        0.030     &     3.547  &         0.000        &        0.047    &        0.163     \\\\\n",
       "\\textbf{publisher\\_АСТ}                   &      -0.1477  &        0.030     &    -4.911  &         0.000        &       -0.207    &       -0.089     \\\\\n",
       "\\textbf{publisher\\_Азбука}                &      -0.2000  &        0.031     &    -6.402  &         0.000        &       -0.261    &       -0.139     \\\\\n",
       "\\textbf{publisher\\_Иностранка}            &      -0.1291  &        0.036     &    -3.621  &         0.000        &       -0.199    &       -0.059     \\\\\n",
       "\\textbf{publisher\\_Манн, Иванов и Фербер} &       0.0127  &        0.041     &     0.313  &         0.754        &       -0.067    &        0.092     \\\\\n",
       "\\textbf{publisher\\_Эксмо}                 &      -0.1713  &        0.030     &    -5.617  &         0.000        &       -0.231    &       -0.111     \\\\\n",
       "\\textbf{publication\\_year\\_2021}          &      -0.0061  &        0.045     &    -0.133  &         0.894        &       -0.095    &        0.083     \\\\\n",
       "\\textbf{publication\\_year\\_2022}          &       0.0386  &        0.038     &     1.016  &         0.310        &       -0.036    &        0.113     \\\\\n",
       "\\textbf{publication\\_year\\_2023}          &       0.0400  &        0.037     &     1.095  &         0.274        &       -0.032    &        0.112     \\\\\n",
       "\\textbf{publication\\_year\\_2024}          &       0.0580  &        0.036     &     1.614  &         0.107        &       -0.012    &        0.128     \\\\\n",
       "\\textbf{publication\\_year\\_2025}          &       0.0672  &        0.036     &     1.858  &         0.063        &       -0.004    &        0.138     \\\\\n",
       "\\textbf{cover\\_type\\_Мягкий переплёт}     &      -0.2338  &        0.230     &    -1.015  &         0.310        &       -0.685    &        0.218     \\\\\n",
       "\\textbf{cover\\_type\\_Твёрдый переплёт}    &      -0.0790  &        0.230     &    -0.343  &         0.731        &       -0.530    &        0.372     \\\\\n",
       "\\textbf{reading\\_age\\_0+}                 &      -0.0317  &        0.144     &    -0.221  &         0.825        &       -0.313    &        0.250     \\\\\n",
       "\\textbf{reading\\_age\\_12+}                &      -0.2551  &        0.051     &    -5.025  &         0.000        &       -0.355    &       -0.156     \\\\\n",
       "\\textbf{reading\\_age\\_16+}                &      -0.1734  &        0.050     &    -3.462  &         0.001        &       -0.272    &       -0.075     \\\\\n",
       "\\textbf{reading\\_age\\_18+}                &      -0.0390  &        0.054     &    -0.727  &         0.467        &       -0.144    &        0.066     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 471.757 & \\textbf{  Durbin-Watson:     } &    2.004  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5130.534  \\\\\n",
       "\\textbf{Skew:}          &  -0.304 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   9.116 & \\textbf{  Cond. No.          } & 1.03e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.03e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              log_price   R-squared:                       0.804\n",
       "Model:                            OLS   Adj. R-squared:                  0.802\n",
       "Method:                 Least Squares   F-statistic:                     389.4\n",
       "Date:                Mon, 05 May 2025   Prob (F-statistic):               0.00\n",
       "Time:                        17:37:26   Log-Likelihood:                 184.00\n",
       "No. Observations:                3260   AIC:                            -298.0\n",
       "Df Residuals:                    3225   BIC:                            -84.86\n",
       "Df Model:                          34                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "const                               5.8943      0.280     21.032      0.000       5.345       6.444\n",
       "tirage                             -0.1782      0.010    -17.857      0.000      -0.198      -0.159\n",
       "avg_rating                          0.0731      0.012      6.256      0.000       0.050       0.096\n",
       "cnt_reviews                         0.0004   3.51e-05     10.025      0.000       0.000       0.000\n",
       "pages_cnt                          -0.0003   4.17e-05     -7.621      0.000      -0.000      -0.000\n",
       "weight                              0.0022   4.78e-05     45.115      0.000       0.002       0.002\n",
       "thickness                           0.1769      0.022      8.167      0.000       0.134       0.219\n",
       "width                               0.0760      0.005     14.086      0.000       0.065       0.087\n",
       "length                              0.0247      0.004      6.256      0.000       0.017       0.032\n",
       "volume                             -0.0012      8e-05    -14.696      0.000      -0.001      -0.001\n",
       "author_Джейн Остен                  0.0134      0.028      0.469      0.639      -0.042       0.069\n",
       "author_Джек Лондон                 -0.0741      0.028     -2.678      0.007      -0.128      -0.020\n",
       "author_Джордж Оруэлл                0.0155      0.029      0.526      0.599      -0.042       0.073\n",
       "author_Лев Толстой                 -0.1152      0.031     -3.681      0.000      -0.177      -0.054\n",
       "author_Луиза Мэй Олкотт            -0.0343      0.033     -1.048      0.295      -0.098       0.030\n",
       "author_Михаил Булгаков              0.0616      0.027      2.285      0.022       0.009       0.114\n",
       "author_Николай Гоголь              -0.0944      0.033     -2.843      0.004      -0.159      -0.029\n",
       "author_Федор Достоевский           -0.1019      0.021     -4.813      0.000      -0.143      -0.060\n",
       "author_Эрих Ремарк                  0.1047      0.030      3.547      0.000       0.047       0.163\n",
       "publisher_АСТ                      -0.1477      0.030     -4.911      0.000      -0.207      -0.089\n",
       "publisher_Азбука                   -0.2000      0.031     -6.402      0.000      -0.261      -0.139\n",
       "publisher_Иностранка               -0.1291      0.036     -3.621      0.000      -0.199      -0.059\n",
       "publisher_Манн, Иванов и Фербер     0.0127      0.041      0.313      0.754      -0.067       0.092\n",
       "publisher_Эксмо                    -0.1713      0.030     -5.617      0.000      -0.231      -0.111\n",
       "publication_year_2021              -0.0061      0.045     -0.133      0.894      -0.095       0.083\n",
       "publication_year_2022               0.0386      0.038      1.016      0.310      -0.036       0.113\n",
       "publication_year_2023               0.0400      0.037      1.095      0.274      -0.032       0.112\n",
       "publication_year_2024               0.0580      0.036      1.614      0.107      -0.012       0.128\n",
       "publication_year_2025               0.0672      0.036      1.858      0.063      -0.004       0.138\n",
       "cover_type_Мягкий переплёт         -0.2338      0.230     -1.015      0.310      -0.685       0.218\n",
       "cover_type_Твёрдый переплёт        -0.0790      0.230     -0.343      0.731      -0.530       0.372\n",
       "reading_age_0+                     -0.0317      0.144     -0.221      0.825      -0.313       0.250\n",
       "reading_age_12+                    -0.2551      0.051     -5.025      0.000      -0.355      -0.156\n",
       "reading_age_16+                    -0.1734      0.050     -3.462      0.001      -0.272      -0.075\n",
       "reading_age_18+                    -0.0390      0.054     -0.727      0.467      -0.144       0.066\n",
       "==============================================================================\n",
       "Omnibus:                      471.757   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5130.534\n",
       "Skew:                          -0.304   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.116   Cond. No.                     1.03e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.03e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_log = ['tirage']\n",
    "cols_not_to_log = [col for col in cols_to_try_log if col not in cols_to_log] + unconditional_cols\n",
    "\n",
    "X_log = np.log(data.loc[:, cols_to_log])\n",
    "X_not_to_log = data.loc[:, cols_not_to_log]\n",
    "\n",
    "X_log_model = sm.add_constant(pd.concat((X_log, X_not_to_log), axis=1))\n",
    "\n",
    "log_model = sm.OLS(data['log_price'], X_log_model).fit()\n",
    "log_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828404e",
   "metadata": {},
   "source": [
    "**мини-вопрос на подумать:** допустим, мы попробовали разные функциональные формы для призаков и в качестве того, для чего резонно применять `log` и `custom_func` у нас функция выдала один и тот же признак `tirage`. Что с ним делать?\n",
    "<br>\n",
    "<br>\n",
    "**\"ответ\":** я предлагаю сильно не заморачиваться и выбрать что придется"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
